#!/usr/bin/env python3
"""
JobScanner Test Crawler

Quick test to verify the crawler functionality with limited scope.
"""

import sys
import os
import logging

# Add the parent directory to the path so we can import jobscanner modules
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from jobscanner.crawler import JobCrawler
from jobscanner.db import JobDatabase

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main():
    """Test crawler with limited scope."""
    logger.info("üß™ Running JobScanner test crawl...")
    
    try:
        # Initialize database
        db = JobDatabase("jobs.db")
        
        # Initialize crawler
        crawler = JobCrawler()
        
        # Test with limited search terms and locations
        test_terms = ['Staff Engineer', 'VP Engineering']
        test_locations = ['Israel', 'United Kingdom']
        
        logger.info("üîç Testing improved crawler with location targeting...")
        try:
            # Test the full crawl_all_sources method with location targeting
            all_jobs = crawler.crawl_all_sources(test_terms, test_locations)
            logger.info(f"‚úÖ Location-targeted crawl: Found {len(all_jobs)} jobs")
            
            # Show sample jobs if found
            if all_jobs:
                for i, job in enumerate(all_jobs[:3]):  # Show first 3 jobs
                    if crawler._is_text_valid(job.get('title', '')) and crawler._is_text_valid(job.get('company', '')):
                        logger.info(f"üìã Sample job {i+1}: {job['title']} @ {job['company']} ({job.get('location', 'Unknown')})")
                        
                        # Test database insertion for first job
                        if i == 0:
                            job_id = db.insert_job(job)
                            if job_id:
                                logger.info(f"‚úÖ Database test: Saved job with ID {job_id}")
                            else:
                                logger.info("‚ÑπÔ∏è  Database test: Job already exists (duplicate)")
        
        except Exception as e:
            logger.error(f"‚ùå Location-targeted crawl test failed: {e}")
        
        # Test individual LinkedIn crawler
        logger.info("üîç Testing LinkedIn crawler directly...")
        try:
            linkedin_jobs = crawler.crawl_linkedin_jobs(test_terms, max_results=3, locations=['Israel'])
            logger.info(f"‚úÖ LinkedIn Israel test: Found {len(linkedin_jobs)} jobs")
            
            if linkedin_jobs:
                for job in linkedin_jobs:
                    if crawler._is_text_valid(job.get('title', '')) and crawler._is_text_valid(job.get('company', '')):
                        logger.info(f"üìã LinkedIn job: {job['title']} @ {job['company']} ({job.get('location', 'Unknown')})")
        
        except Exception as e:
            logger.error(f"‚ùå LinkedIn direct test failed: {e}")
        
        # Final database stats
        stats = db.get_stats()
        logger.info(f"üìä Final database stats: {stats}")
        
        logger.info("üéâ Test crawl completed!")
        
    except Exception as e:
        logger.error(f"üí• Test failed: {e}")
        raise


if __name__ == "__main__":
    main() 